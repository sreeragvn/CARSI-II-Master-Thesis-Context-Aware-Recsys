{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTEBOOK FOR UNDERSAMPLING STRATEGIES\n",
    "# remove all the consecutive duplicate clicks in a sample\n",
    "# remove all the duplicate rows of clicks in the entire df  \n",
    "#todo fix timedelta. right now the transformation for the time delta is ignored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_num_mapping_start = 1\n",
    "model_test_run = False #This reduces the data generated by selecting significantly lesser number of sessions to test the model\n",
    "remove_consecutive_identical_clicks = False\n",
    "#Todo implement identical consecutive clicks - only do that if the timedelta between clicks is quite less- otherwise it doesnt make sense.\n",
    "sequence_augmentation = True\n",
    "carsi_labels_only = True\n",
    "regenerate_context_data = False\n",
    "whole_session_context = False\n",
    "data_autoencoder = False\n",
    "pad_to_window_size = True\n",
    "window = 100 #seconds\n",
    "\n",
    "base_path = '../datasets/sequential/'\n",
    "combined_context_path = '../data/05_Interaction_Sequences/context.csv'\n",
    "augmentation_folder = 'aug/' if sequence_augmentation else 'non_aug/'\n",
    "if model_test_run:\n",
    "    augmentation_folder = 'test/aug/' if sequence_augmentation else 'test/non_aug/'\n",
    "sequence_context_path = f'{base_path}{augmentation_folder}parameters/sequence_context.csv'\n",
    "parameter_path = f'{base_path}{augmentation_folder}parameters'\n",
    "sequence_path = f'{base_path}{augmentation_folder}seq'\n",
    "train_session_path = f'{base_path}{augmentation_folder}parameters/train_sessions.pkl'\n",
    "test_session_path = f'{base_path}{augmentation_folder}parameters/test_sessions.pkl'\n",
    "train_dynamic_context_path = f'{base_path}{augmentation_folder}dynamic_context/train.csv'\n",
    "test_dynamic_context_path = f'{base_path}{augmentation_folder}dynamic_context/test.csv'\n",
    "train_static_context_path = f'{base_path}{augmentation_folder}static_context/train.csv'\n",
    "test_static_context_path = f'{base_path}{augmentation_folder}static_context/test.csv'\n",
    "\n",
    "dc_train_unnor_path = '../datasets/sequential/aug/dynamic_context/unnormal/train.csv'\n",
    "dc_test_unnor_path = '../datasets/sequential/aug/dynamic_context/unnormal/test.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dc_train = pd.read_csv(train_dynamic_context_path)\n",
    "# dc_test = pd.read_csv(test_dynamic_context_path)\n",
    "\n",
    "dc_train = pd.read_csv(dc_train_unnor_path)\n",
    "dc_test = pd.read_csv(dc_test_unnor_path)\n",
    "\n",
    "sc_train = pd.read_csv(train_static_context_path)\n",
    "sc_test = pd.read_csv(test_static_context_path)\n",
    "\n",
    "seq_train = pd.read_csv(sequence_path+'/train.tsv', sep='\\t')\n",
    "seq_test = pd.read_csv(sequence_path+'/test.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum length of lists in seq_list column: 53\n",
      "There are no empty lists in the 'seq_list' column.\n",
      "Maximum length of lists in seq_list column: 38\n",
      "There are no empty lists in the 'seq_list' column.\n"
     ]
    }
   ],
   "source": [
    "def remove_consecutive_duplicates(input_list):\n",
    "    result = []\n",
    "    removed_indices = []  # List to store indices of removed elements\n",
    "    prev = None\n",
    "    for i, num in enumerate(input_list):\n",
    "        if num != prev:\n",
    "            result.append(num)\n",
    "        else:\n",
    "            removed_indices.append(i)\n",
    "        prev = num\n",
    "    return result, removed_indices\n",
    "\n",
    "def join_list(lst):\n",
    "    return ' '.join(map(str, lst))\n",
    "\n",
    "def create_zeros_list(lst):\n",
    "    return [0] * len(lst)\n",
    "    \n",
    "def seq_duplicate_remove(df, datasettype):\n",
    "    df['interaction_time_delta_train_list'] = df['interaction_time_delta_train'].str.split().apply(lambda x: [int(i) for i in x])\n",
    "    result = df['item_id_seq_train'].str.split().apply(lambda x: remove_consecutive_duplicates([int(i) for i in x]))\n",
    "    # Extract cleaned list and removed indices into separate columns\n",
    "    df['seq_list'] = result.apply(lambda x: x[0])\n",
    "    df['removed_indices'] = result.apply(lambda x: x[1])\n",
    "    \n",
    "    df['seq_non_dup'] = df['seq_list'].apply(join_list)\n",
    "\n",
    "    max_length = df['seq_list'].apply(lambda x: len(x)).max()\n",
    "    print(\"Maximum length of lists in seq_list column:\", max_length)\n",
    "\n",
    "    empty_lists_exist = any(df['seq_list'].apply(lambda x: len(x) == 0))\n",
    "    if empty_lists_exist:\n",
    "        print(\"There are empty lists in the 'seq_list' column.\")\n",
    "    else:\n",
    "        print(\"There are no empty lists in the 'seq_list' column.\")\n",
    "\n",
    "    df['wrong_time_delta_interaction_list'] = df['seq_list'].apply(create_zeros_list)\n",
    "    df['wrong_time_delta_interaction'] = df['wrong_time_delta_interaction_list'].apply(join_list)\n",
    "\n",
    "    df.drop(columns=['seq_list', 'item_id_seq_train'], inplace=True)\n",
    "    df.rename(columns={'seq_non_dup': 'item_id_seq_train'}, inplace=True)\n",
    "\n",
    "    desired_column_order = ['window_id', 'item_id_seq_train', 'item_id_target', 'wrong_time_delta_interaction', 'session']\n",
    "    df = df[desired_column_order]\n",
    "    return df\n",
    "\n",
    "seq_train_updated = seq_duplicate_remove(seq_train, 'train')\n",
    "seq_test_updated = seq_duplicate_remove(seq_test, 'test')\n",
    "\n",
    "# seq_test_updated.to_csv(os.path.join(sequence_path, 'non_dup' ,'test.tsv'), sep='\\t', index=False)\n",
    "# seq_train_updated.to_csv(os.path.join(sequence_path, 'non_dup' ,'train.tsv'), sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Todo to fix the timedelta after deleting the duplicates\n",
    "\n",
    "# def split_consecutive(numbers):\n",
    "#     if not numbers:\n",
    "#         return []\n",
    "\n",
    "#     # Initialize the list of lists to store consecutive sequences\n",
    "#     result = [[numbers[0]]]\n",
    "\n",
    "#     # Iterate through the numbers\n",
    "#     for num in numbers[1:]:\n",
    "#         # If the current number is consecutive to the last number in the last sublist\n",
    "#         if num == result[-1][-1] + 1:\n",
    "#             result[-1].append(num)  # Add it to the current sublist\n",
    "#         else:\n",
    "#             result.append([num])  # Otherwise, start a new sublist\n",
    "\n",
    "#     return result\n",
    "\n",
    "\n",
    "# def update_time_delta(row):\n",
    "#     time_delta_list = row['interaction_time_delta_train_list']\n",
    "    \n",
    "#     removed_indices = row['removed_indices']\n",
    "#     # print(time_delta_list)\n",
    "#     # print(removed_indices)\n",
    "#     updated_time_delta = []  # Initialize updated_time_delta variable\n",
    "    \n",
    "#     split = split_consecutive(removed_indices)\n",
    "\n",
    "#     if len(removed_indices) != 0:\n",
    "#         # for i in range(1, len(time_delta_list)):\n",
    "#         #     if i not in removed_indices:\n",
    "#         #         updated_time_delta.append(time_delta_list[i])\n",
    "#         #     else:\n",
    "#         #         new_time_delta = time_delta_list[i] + time_delta_list[i-1]\n",
    "#         #         updated_time_delta.append(new_time_delta)\n",
    "#         for count, i in enumerate(split):\n",
    "#             print('count', count)\n",
    "#             if count == 0:\n",
    "#                 print('inside count =0', i)\n",
    "#                 new_time_delta = time_delta_list[i[0]-1]\n",
    "#             else:\n",
    "#                 print('i am here')\n",
    "#                 print(i)\n",
    "#                 print(new_time_delta)\n",
    "#                 new_time_delta = updated_time_delta[-1]\n",
    "#                 print(new_time_delta)\n",
    "#             for j in i:\n",
    "#                 print('inside for loop',j)\n",
    "#                 new_time_delta = new_time_delta + time_delta_list[j]\n",
    "#             updated_time_delta.append(new_time_delta)\n",
    "#     else:\n",
    "#         updated_time_delta = time_delta_list  # Assign original time_delta_list\n",
    "    \n",
    "#     return updated_time_delta  # Return the updated list\n",
    "\n",
    "# seq_train_updated['updated_interaction_time_delta'] = seq_train_updated[['interaction_time_delta_train_list', 'removed_indices']].apply(update_time_delta, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/n8/1ntcg5gj7nvf5wh_s2w95yh80000gn/T/ipykernel_3878/3025388035.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  seq_train_updated['dup_check'] = seq_train_updated['item_id_seq_train'] + '_' + seq_train_updated['item_id_target'].astype(str)\n",
      "/var/folders/n8/1ntcg5gj7nvf5wh_s2w95yh80000gn/T/ipykernel_3878/3025388035.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  duplicate_rows['dup_item_id_seq_train_list'] = duplicate_rows['item_id_seq_train'].str.split().apply(lambda x: [int(i) for i in x])\n",
      "/var/folders/n8/1ntcg5gj7nvf5wh_s2w95yh80000gn/T/ipykernel_3878/3025388035.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  duplicate_rows['item_id_sum'] = duplicate_rows['dup_item_id_seq_train_list'].apply(lambda x: sum(x))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>window_id</th>\n",
       "      <th>item_id_seq_train</th>\n",
       "      <th>item_id_target</th>\n",
       "      <th>wrong_time_delta_interaction</th>\n",
       "      <th>session</th>\n",
       "      <th>dup_check</th>\n",
       "      <th>dup_item_id_seq_train_list</th>\n",
       "      <th>item_id_sum</th>\n",
       "      <th>dup_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1265</th>\n",
       "      <td>1265</td>\n",
       "      <td>1 15 2</td>\n",
       "      <td>7</td>\n",
       "      <td>0 0 0</td>\n",
       "      <td>1401.0</td>\n",
       "      <td>1 15 2_7</td>\n",
       "      <td>[1, 15, 2]</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1361</th>\n",
       "      <td>1361</td>\n",
       "      <td>1 15 2</td>\n",
       "      <td>7</td>\n",
       "      <td>0 0 0</td>\n",
       "      <td>1565.0</td>\n",
       "      <td>1 15 2_7</td>\n",
       "      <td>[1, 15, 2]</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1362</th>\n",
       "      <td>1362</td>\n",
       "      <td>1 15</td>\n",
       "      <td>2</td>\n",
       "      <td>0 0</td>\n",
       "      <td>1565.0</td>\n",
       "      <td>1 15_2</td>\n",
       "      <td>[1, 15]</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1266</th>\n",
       "      <td>1266</td>\n",
       "      <td>1 15</td>\n",
       "      <td>2</td>\n",
       "      <td>0 0</td>\n",
       "      <td>1401.0</td>\n",
       "      <td>1 15_2</td>\n",
       "      <td>[1, 15]</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1024</th>\n",
       "      <td>1024</td>\n",
       "      <td>1 15</td>\n",
       "      <td>7</td>\n",
       "      <td>0 0</td>\n",
       "      <td>1311.0</td>\n",
       "      <td>1 15_7</td>\n",
       "      <td>[1, 15]</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2957</th>\n",
       "      <td>2957</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>3953.0</td>\n",
       "      <td>9_9</td>\n",
       "      <td>[9]</td>\n",
       "      <td>9</td>\n",
       "      <td>365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2963</th>\n",
       "      <td>2963</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>3959.0</td>\n",
       "      <td>9_9</td>\n",
       "      <td>[9]</td>\n",
       "      <td>9</td>\n",
       "      <td>365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2956</th>\n",
       "      <td>2956</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>3953.0</td>\n",
       "      <td>9_9</td>\n",
       "      <td>[9]</td>\n",
       "      <td>9</td>\n",
       "      <td>365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2955</th>\n",
       "      <td>2955</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>3953.0</td>\n",
       "      <td>9_9</td>\n",
       "      <td>[9]</td>\n",
       "      <td>9</td>\n",
       "      <td>365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2954</th>\n",
       "      <td>2954</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>3953.0</td>\n",
       "      <td>9_9</td>\n",
       "      <td>[9]</td>\n",
       "      <td>9</td>\n",
       "      <td>365</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2547 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      window_id item_id_seq_train  item_id_target  \\\n",
       "1265       1265            1 15 2               7   \n",
       "1361       1361            1 15 2               7   \n",
       "1362       1362              1 15               2   \n",
       "1266       1266              1 15               2   \n",
       "1024       1024              1 15               7   \n",
       "...         ...               ...             ...   \n",
       "2957       2957                 9               9   \n",
       "2963       2963                 9               9   \n",
       "2956       2956                 9               9   \n",
       "2955       2955                 9               9   \n",
       "2954       2954                 9               9   \n",
       "\n",
       "     wrong_time_delta_interaction  session dup_check  \\\n",
       "1265                        0 0 0   1401.0  1 15 2_7   \n",
       "1361                        0 0 0   1565.0  1 15 2_7   \n",
       "1362                          0 0   1565.0    1 15_2   \n",
       "1266                          0 0   1401.0    1 15_2   \n",
       "1024                          0 0   1311.0    1 15_7   \n",
       "...                           ...      ...       ...   \n",
       "2957                            0   3953.0       9_9   \n",
       "2963                            0   3959.0       9_9   \n",
       "2956                            0   3953.0       9_9   \n",
       "2955                            0   3953.0       9_9   \n",
       "2954                            0   3953.0       9_9   \n",
       "\n",
       "     dup_item_id_seq_train_list  item_id_sum  dup_id  \n",
       "1265                 [1, 15, 2]           18       0  \n",
       "1361                 [1, 15, 2]           18       0  \n",
       "1362                    [1, 15]           16       1  \n",
       "1266                    [1, 15]           16       1  \n",
       "1024                    [1, 15]           16       2  \n",
       "...                         ...          ...     ...  \n",
       "2957                        [9]            9     365  \n",
       "2963                        [9]            9     365  \n",
       "2956                        [9]            9     365  \n",
       "2955                        [9]            9     365  \n",
       "2954                        [9]            9     365  \n",
       "\n",
       "[2547 rows x 9 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_train_updated['dup_check'] = seq_train_updated['item_id_seq_train'] + '_' + seq_train_updated['item_id_target'].astype(str)\n",
    "duplicate_rows = seq_train_updated[seq_train_updated.duplicated(subset=['dup_check'], keep=False)]\n",
    "duplicate_rows['dup_item_id_seq_train_list'] = duplicate_rows['item_id_seq_train'].str.split().apply(lambda x: [int(i) for i in x])\n",
    "duplicate_rows['item_id_sum'] = duplicate_rows['dup_item_id_seq_train_list'].apply(lambda x: sum(x))\n",
    "duplicate_rows = duplicate_rows.sort_values(by=['item_id_sum', 'item_id_target'])\n",
    "duplicate_rows['dup_id'] = duplicate_rows.groupby('dup_check').ngroup()\n",
    "# duplicate_rows['dup_id'] = duplicate_rows['dup_id'] - duplicate_rows['dup_id'].min()\n",
    "duplicate_rows = duplicate_rows.sort_values(by='dup_id')\n",
    "duplicate_rows.to_csv('duplicate rows.csv')\n",
    "duplicate_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_dc(df):\n",
    "    unique_window_ids = df['window_id'].unique()\n",
    "    num_subplots = len(df.columns)\n",
    "    num_unique_ids = len(unique_window_ids)\n",
    "\n",
    "    fig, axes = plt.subplots(nrows=num_subplots, ncols=num_unique_ids, figsize=(12*num_unique_ids, 6*num_subplots))\n",
    "\n",
    "    for i, column in enumerate(df.columns):\n",
    "        for j, window_id in enumerate(unique_window_ids):\n",
    "            data_subset = df[df['window_id'] == window_id]\n",
    "            axes[i, j].plot(data_subset.index, data_subset[column])\n",
    "            axes[i, j].set_title(f\"{column} - Window ID {window_id}\")\n",
    "            axes[i, j].set_xlabel('Index')\n",
    "            axes[i, j].set_ylabel('Values')\n",
    "            axes[i, j].grid(True)\n",
    "            axes[i, j].legend([column], loc='upper left')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['avg_irradiation', 'steering_speed', 'temperature_out',\n",
       "       'light_sensor_rear', 'light_sensor_front', 'temperature_in',\n",
       "       'KBI_speed', 'soc', 'latitude', 'longitude', 'street_category',\n",
       "       'altitude', 'time_second', 'distance_driven', 'window_id', 'session',\n",
       "       'datetime'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dc_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dc_selected = ['avg_irradiation', 'steering_speed', 'temperature_out',\n",
    "       'light_sensor_rear', 'light_sensor_front', 'temperature_in',\n",
    "       'KBI_speed', 'soc', 'latitude', 'longitude', 'street_category',\n",
    "       'altitude', 'time_second', 'distance_driven']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'window_id'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/carsii/lib/python3.8/site-packages/pandas/core/indexes/base.py:3653\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3652\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3653\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3654\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/miniconda3/envs/carsii/lib/python3.8/site-packages/pandas/_libs/index.pyx:147\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/carsii/lib/python3.8/site-packages/pandas/_libs/index.pyx:176\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'window_id'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m dc_train_curr \u001b[38;5;241m=\u001b[39m dc_train[dc_train[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwindow_id\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39misin(window_ids)]\n\u001b[1;32m      5\u001b[0m dc_train_curr \u001b[38;5;241m=\u001b[39m dc_train_curr[dc_selected]\n\u001b[0;32m----> 6\u001b[0m \u001b[43mplot_dc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdc_train_curr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[27], line 2\u001b[0m, in \u001b[0;36mplot_dc\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mplot_dc\u001b[39m(df):\n\u001b[0;32m----> 2\u001b[0m     unique_window_ids \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mwindow_id\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39munique()\n\u001b[1;32m      3\u001b[0m     num_subplots \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(df\u001b[38;5;241m.\u001b[39mcolumns)\n\u001b[1;32m      4\u001b[0m     num_unique_ids \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(unique_window_ids)\n",
      "File \u001b[0;32m~/miniconda3/envs/carsii/lib/python3.8/site-packages/pandas/core/frame.py:3761\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   3760\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3761\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3762\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3763\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/miniconda3/envs/carsii/lib/python3.8/site-packages/pandas/core/indexes/base.py:3655\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3653\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3654\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m-> 3655\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3656\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3657\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3658\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3659\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3660\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'window_id'"
     ]
    }
   ],
   "source": [
    "for dup in sorted(duplicate_rows.dup_id.unique().tolist()):\n",
    "    row = duplicate_rows[duplicate_rows['dup_id']==dup]\n",
    "    window_ids = row.window_id.tolist()\n",
    "    dc_train_curr = dc_train[dc_train['window_id'].isin(window_ids)]\n",
    "    dc_train_curr = dc_train_curr[dc_selected]\n",
    "    plot_dc(dc_train_curr)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2547"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(duplicate_rows['window_id'].unique().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "929"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(duplicate_rows['session'].unique().tolist())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "carsii",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
