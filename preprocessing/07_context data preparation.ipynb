{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, RobustScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regenerate_context_data = True\n",
    "sequence_augmentation = True\n",
    "whole_session_context = False\n",
    "model_test_run = False\n",
    "data_autoencoder = False\n",
    "pad_to_window_size = True\n",
    "feat_engg = True\n",
    "\n",
    "PATH_TO_LOAD = '../data/04_Merged'\n",
    "if feat_engg:\n",
    "    combined_context_path = '../data/06_context_feat_engg/data_featue_engineering.csv'\n",
    "    augmentation_folder = 'featengg/' if sequence_augmentation else 'non_aug/'\n",
    "else:\n",
    "    combined_context_path = '../data/05_Interaction_Sequences/context.csv'\n",
    "    augmentation_folder = 'fix/' if sequence_augmentation else 'non_aug/'\n",
    "\n",
    "window = 30 #seconds\n",
    "\n",
    "base_path = '../datasets/sequential/'\n",
    "if model_test_run:\n",
    "    augmentation_folder = 'test/aug/' if sequence_augmentation else 'test/non_aug/'\n",
    "\n",
    "sequence_context_path = f'{base_path}{augmentation_folder}parameters/sequence_context.csv'\n",
    "parameter_path = f'{base_path}{augmentation_folder}parameters'\n",
    "train_session_path = f'{base_path}{augmentation_folder}parameters/train_sessions.pkl'\n",
    "test_session_path = f'{base_path}{augmentation_folder}parameters/test_sessions.pkl'\n",
    "train_dynamic_context_path = f'{base_path}{augmentation_folder}dynamic_context/train.csv'\n",
    "test_dynamic_context_path = f'{base_path}{augmentation_folder}dynamic_context/test.csv'\n",
    "train_static_context_path = f'{base_path}{augmentation_folder}static_context/train.csv'\n",
    "test_static_context_path = f'{base_path}{augmentation_folder}static_context/test.csv'\n",
    "train_sequence_path = f'{base_path}{augmentation_folder}seq/train.tsv'\n",
    "test_sequence_path = f'{base_path}{augmentation_folder}seq/test.tsv'\n",
    "train_dense_static_context_path = f'{base_path}{augmentation_folder}dense_static_context/train.csv'\n",
    "test_dense_static_context_path = f'{base_path}{augmentation_folder}dense_static_context/test.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_columns = ['index', 'avg_irradiation', 'steering_speed', 'temperature_out', 'hour',\n",
    "       'month', 'odometer', 'light_sensor_rear', 'light_sensor_front',\n",
    "       'temperature_in', 'KBI_speed', 'soc', 'ESP_speed', 'latitude',\n",
    "       'longitude', 'seatbelt_codriver', 'seatbelt_rear_l', 'seatbelt_rear_m',\n",
    "       'seatbelt_rear_r', 'CHA_ESP_drive_mode', 'CHA_MO_drive_mode',\n",
    "       'rain_sensor', 'street_category', 'kickdown', 'altitude',\n",
    "       'driving_program', 'datetime', 'session', 'Label', 'ID',\n",
    "       'FunctionValue', 'domain', 'BeginTime', 'time_second',\n",
    "       'distance_driven', 'ts_normalized', 'weekday']\n",
    "\n",
    "selected = [ 'avg_irradiation', 'steering_speed', 'temperature_out', 'hour',\n",
    "       'month', 'light_sensor_rear', 'light_sensor_front',\n",
    "       'temperature_in', 'KBI_speed', 'soc', 'latitude',\n",
    "       'longitude', 'seatbelt_codriver', 'seatbelt_rear_l',\n",
    "       'seatbelt_rear_r', 'street_category', 'altitude',\n",
    "       'datetime', 'session', 'time_second',\n",
    "       'distance_driven', 'weekday'\n",
    "]\n",
    "\n",
    "bad_quality = ['CHA_ESP_drive_mode', \n",
    "             'CHA_MO_drive_mode',\n",
    "             'rain_sensor',\n",
    "             'kickdown',\n",
    "             'ESP_speed',\n",
    "             'seatbelt_rear_m',\n",
    "            'driving_program',\n",
    "            'ts_normalized'\n",
    "             ]\n",
    "\n",
    "dynamic_context_var = ['avg_irradiation', 'steering_speed', 'temperature_out', \n",
    "                       'light_sensor_rear', 'light_sensor_front', \n",
    "                       'temperature_in', 'KBI_speed', \n",
    "                       'latitude','longitude', 'altitude'] # todo remove these features in the future\n",
    "if feat_engg:\n",
    "       cat_static_context_var = ['car_id', 'month', 'weekday', 'hour', 'season', 'seatbelt_codriver', 'seatbelt_rear_l', # categorical static context\n",
    "                            'seatbelt_rear_r',  'street_category']\n",
    "else:\n",
    "       cat_static_context_var = ['car_id', 'month', 'weekday', 'hour', 'seatbelt_codriver', 'seatbelt_rear_l', # categorical static context\n",
    "                            'seatbelt_rear_r',  'street_category']\n",
    "dense_static_context_var =  ['distance_driven_benchmark', 'soc', 'time_second']  # dense static context\n",
    "status_static_context_var = ['ess_status', 'current_drive_mode', 'current_clima_mode', 'current_media_source', # status static context\n",
    "                     'nav_guidance_status', 'proximity_to_parking_spot', 'phone_status',\n",
    "                     'bluetooth_connected', 'phone_os',\n",
    "                     'new_bluetooth_device_to_pair']\n",
    "#todo i feel street category is higly fluctuating. might be better to ignore\n",
    "vehicles = ['SEB880','SEB882','SEB883','SEB885','SEB888','SEB889']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if feat_engg:\n",
    "    context_data = pd.read_csv(combined_context_path, parse_dates=['datetime'], index_col=0, low_memory=False)\n",
    "else:\n",
    "    context_data = pd.read_csv(combined_context_path, parse_dates=['datetime'], low_memory=False)\n",
    "    \n",
    "context_data_filtered = context_data[context_data['distance_driven'] != 0]\n",
    "context_data_filtered['distance_driven_benchmark'] = context_data_filtered.groupby('session')['distance_driven'].transform(lambda x: x - x.min())\n",
    "context_data['distance_driven_benchmark'] = context_data_filtered['distance_driven_benchmark']\n",
    "context_data['distance_driven_benchmark'].fillna(0, inplace=True)\n",
    "context_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_data_list = []\n",
    "for session in tqdm(context_data.session.unique().tolist()):\n",
    "    context_data_curr = context_data[context_data['session']== session]\n",
    "    context_data_curr['distance_driven_benchmark'] = context_data_curr['distance_driven_benchmark'].replace(0, method='ffill')\n",
    "    context_data_list.append(context_data_curr)\n",
    "context_data = pd.concat(context_data_list, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# # Assuming df is your DataFrame containing the 'session' and 'distance_driven_benchmark' columns\n",
    "\n",
    "# # Group the DataFrame by 'session'\n",
    "# grouped_df = context_data.groupby('session')\n",
    "\n",
    "# # Iterate over each group and create line plots\n",
    "# for session, group in grouped_df:\n",
    "#     plt.figure(figsize=(4, 3)) \n",
    "#     plt.figure()  # Create a new figure for each session\n",
    "#     plt.plot(group.index, group['time_second'], marker='o', linestyle='-')\n",
    "#     plt.title(f'Distance Driven Benchmark for Session {session}')\n",
    "#     plt.xlabel('Index')\n",
    "#     plt.ylabel('Distance Driven Benchmark')\n",
    "#     plt.grid(True)\n",
    "#     plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(train_session_path, 'rb') as pickle_file:\n",
    "    train_sessions = pickle.load(pickle_file)\n",
    "with open(test_session_path, 'rb') as pickle_file:\n",
    "    test_sessions = pickle.load(pickle_file)\n",
    "context_data = context_data[context_data['session'].isin(train_sessions + test_sessions)]\n",
    "\n",
    "train_sequence = pd.read_csv(train_sequence_path, sep='\\t', low_memory=False)\n",
    "test_sequence = pd.read_csv(test_sequence_path, sep='\\t', low_memory=False)\n",
    "selected_sequence = pd.concat([train_sequence, test_sequence], axis=0).sort_values(['session', 'window_id'])\n",
    "\n",
    "# selected_sequence = pd.read_csv(sequence_context_path, parse_dates=['datetime'], index_col=0)\n",
    "# selected_sequence['session'] = selected_sequence['session'].astype(int)\n",
    "# min_datetime_indices = selected_sequence.groupby('session')['datetime'].idxmin()\n",
    "# selected_sequence = selected_sequence.drop(min_datetime_indices)\n",
    "# selected_sequence.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# selected_dfs = []\n",
    "# for session in tqdm(selected_sequence['session'].unique().tolist()):\n",
    "#     selected_sequence_curr = selected_sequence[selected_sequence['session']==session]\n",
    "#     context_data_curr = context_data[context_data['session']==session]\n",
    "#     context_data_curr = context_data_curr[context_data_curr['datetime']<=selected_sequence_curr['timestamp_target_interaction'].max()]\n",
    "#     selected_dfs.append(context_data_curr)\n",
    "# training_sequence_context = pd.concat(selected_dfs, axis=0)\n",
    "training_sequence_context = context_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(context_data.session.unique().tolist()), \n",
    "      len(training_sequence_context.session.unique().tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if sequence_augmentation == True:\n",
    "    augmented_frames = []\n",
    "    for index, row in tqdm(selected_sequence.iterrows(), total=len(selected_sequence)):\n",
    "        session = row['session']\n",
    "        window_id = row['window_id']\n",
    "        timestamp_target_interaction = row['timestamp_target_interaction']\n",
    "        training_sequence_context_curr = training_sequence_context[(training_sequence_context['session'] == session) &\n",
    "                                                    (training_sequence_context['datetime'] <= timestamp_target_interaction)].copy()\n",
    "        if training_sequence_context_curr.empty:\n",
    "            print(session, window_id)\n",
    "        if not whole_session_context and window < len(training_sequence_context_curr):\n",
    "                training_sequence_context_curr = training_sequence_context_curr.tail(window)\n",
    "        training_sequence_context_curr['window_id'] = window_id\n",
    "        augmented_frames.append(training_sequence_context_curr)\n",
    "        # print(session, window_id, timestamp_target_interaction)\n",
    "        # break\n",
    "    training_sequence_context_augmented = pd.concat(augmented_frames, axis=0)\n",
    "    context_data = training_sequence_context_augmented.reset_index(drop=True)\n",
    "    context_data['wind_id'] = context_data.groupby(['session', 'window_id']).ngroup()\n",
    "else:\n",
    "    # if sequence_augmentation is set to false\n",
    "    if not whole_session_context:\n",
    "        context_data = training_sequence_context.groupby('session').tail(window)\n",
    "    context_data = training_sequence_context.reset_index(drop=True)\n",
    "    context_data['window_id'] = context_data.groupby('session').ngroup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('total number of sequence data sessions: ', len(selected_sequence.session.unique().tolist()))\n",
    "print('total number of Sequence data windows: ', len(train_sequence.window_id.unique().tolist()) + len(test_sequence.window_id.unique().tolist()))\n",
    "print('total number of context data sessions: ', len(context_data.session.unique().tolist()))\n",
    "print('total number of context data windows: ', len(context_data.wind_id.unique().tolist()))\n",
    "#dont be the bothered about the total number of windows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "total number of sequence data sessions:  1634\n",
    "total number of Sequence data windows:  5883\n",
    "total number of context data sessions:  1634\n",
    "total number of context data windows:  5883"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing_sessions = [16, 25]\n",
    "# selected_sequence = selected_sequence[selected_sequence['session'].isin(testing_sessions)]\n",
    "# training_sequence_context = training_sequence_context[training_sequence_context['session'].isin(testing_sessions)]\n",
    "\n",
    "# window_id = 0\n",
    "# if sequence_augmentation == True:\n",
    "#     grouped_selected_sequence = selected_sequence.groupby('session')\n",
    "#     augmented_frames = []\n",
    "#     for session, selected_sequence_curr in tqdm(grouped_selected_sequence):\n",
    "#         for i, row in selected_sequence_curr.iloc[::-1].iterrows():\n",
    "#             context_filt_curr = training_sequence_context[\n",
    "#                 (training_sequence_context['session'] == session) &\n",
    "#                 (training_sequence_context['datetime'] < row['datetime'])].copy()\n",
    "#             if not whole_session_context:\n",
    "#                 context_filt_curr = context_filt_curr.tail(window)\n",
    "#             context_filt_curr['window_id'] = window_id\n",
    "#             # context_filt_curr['session'] = session\n",
    "#             augmented_frames.append(context_filt_curr)\n",
    "#             window_id += 1\n",
    "#     training_sequence_context_augmented = pd.concat(augmented_frames, axis=0)\n",
    "#     context_data = training_sequence_context_augmented.reset_index(drop=True)\n",
    "# else:\n",
    "#     # if sequence_augmentation is set to false\n",
    "#     if not whole_session_context:\n",
    "#         context_data = training_sequence_context.groupby('session').tail(window)\n",
    "#     context_data = training_sequence_context.reset_index(drop=True)\n",
    "#     context_data['window_id'] = context_data.groupby('session').ngroup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dynamic_context = context_data[dynamic_context_var + ['window_id', 'session', 'datetime', 'wind_id']]\n",
    "print('number of dynamic context session', len(dynamic_context[['window_id', 'session']].drop_duplicates()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Todo we have to do window averaging with wind_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to pad first value to fit the window size\n",
    "if pad_to_window_size:\n",
    "    df = dynamic_context.copy()\n",
    "    session_counts = df.groupby('wind_id').size()\n",
    "    less_than_100 = session_counts[session_counts < window].index.tolist()\n",
    "    print(f'Number of window with window length less than {window}: ', len(less_than_100))\n",
    "    window100_dfs = df[~df['wind_id'].isin(less_than_100)]\n",
    "    empty_df = []\n",
    "    for window_id in tqdm(less_than_100):\n",
    "        sub_df = df[df['wind_id'] == window_id]\n",
    "        rows_to_pad = window - len(sub_df)\n",
    "        min_datetime_row = sub_df.loc[sub_df['datetime'].idxmin()]\n",
    "        pad_df = pd.DataFrame(min_datetime_row, df.columns).transpose()\n",
    "        pad_df = pd.concat([pad_df] * int(rows_to_pad), ignore_index=True, axis=0)\n",
    "\n",
    "        padded_df = pd.concat([pad_df, sub_df], axis=0).reset_index(drop=True)\n",
    "        # padded_df['wind_id'] = window_id\n",
    "        # padded_df['window_id'] = window_id\n",
    "        # padded_df['wind_id'] = window_id\n",
    "        empty_df.append(padded_df)\n",
    "    if empty_df:\n",
    "        df = pd.concat(empty_df, axis=0).reset_index(drop=True)\n",
    "        df = pd.concat([df, window100_dfs], axis=0).sort_values(by=['window_id']).reset_index(drop=True)\n",
    "        session_counts = df.groupby('window_id').size()\n",
    "        less_than_100 = session_counts[session_counts < window].index.tolist()\n",
    "        print(f'Number of window with window length less than {window}: ', len(less_than_100))\n",
    "        dynamic_context = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_static_context = context_data[dense_static_context_var + ['window_id', 'session', 'datetime', 'wind_id']]\n",
    "dense_static_context = dense_static_context.sort_values(by=['wind_id','datetime'], ascending=False)\n",
    "dense_static_context = dense_static_context.groupby('wind_id').first()\n",
    "dense_static_context.reset_index(inplace=True)\n",
    "dense_static_context = dense_static_context.sort_values(by='wind_id')\n",
    "dense_static_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_static_context = context_data[cat_static_context_var + ['window_id', 'session', 'datetime', 'wind_id']]\n",
    "cat_static_context = cat_static_context.groupby('wind_id').apply(lambda x: x.mode().iloc[0]).reset_index(drop=True)\n",
    "if feat_engg:\n",
    "    cat_static_context['season'], _ = pd.factorize(cat_static_context['season'])  \n",
    "\n",
    "    status_static_context = context_data[status_static_context_var + ['window_id', 'session', 'datetime', 'wind_id']]\n",
    "    for col in status_static_context_var:\n",
    "        print(col)\n",
    "        print(sorted(status_static_context[col].unique().tolist()))  \n",
    "    for col in status_static_context_var:\n",
    "        status_static_context[col], _ = pd.factorize(status_static_context[col])  \n",
    "    status_static_context = status_static_context.sort_values(by=['session', 'datetime'])\n",
    "    latest_indices = status_static_context.groupby('wind_id')['datetime'].idxmax()\n",
    "    status_static_context_filt = status_static_context.loc[latest_indices]\n",
    "    status_static_context = status_static_context_filt.reset_index(drop=True)\n",
    "\n",
    "    static_context = pd.merge(cat_static_context, status_static_context, on=['wind_id', 'window_id', 'session'], how='inner')\n",
    "else:\n",
    "    static_context = cat_static_context\n",
    "static_context = static_context.sort_values(by='wind_id')\n",
    "print('number of windows', len(dynamic_context.wind_id.unique().tolist()), len(static_context.wind_id.unique().tolist()))\n",
    "print('number of session', len(dynamic_context.session.unique().tolist()), len(static_context.session.unique().tolist()))\n",
    "static_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dynamic_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "static_context.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dynamic_context.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_static_context.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dynamic_context = dynamic_context.sort_values(by=['wind_id', 'datetime'])\n",
    "static_context = static_context.sort_values(by=['wind_id'])\n",
    "dense_static_context = dense_static_context.sort_values(by=['wind_id', 'datetime'])\n",
    "if feat_engg:\n",
    "    static_context = static_context.drop(columns=['datetime_y', 'datetime_x'])\n",
    "else:\n",
    "    static_context = static_context.drop(columns=['datetime'])\n",
    "\n",
    "# rearrage order of columns\n",
    "columns = list(static_context.columns)\n",
    "columns.remove('car_id')\n",
    "columns.append('car_id')\n",
    "static_context = static_context[columns]\n",
    "\n",
    "dynamic_context = dynamic_context.drop(columns='wind_id')\n",
    "static_context = static_context.drop(columns=['wind_id'])\n",
    "dense_static_context = dense_static_context.drop(columns=['wind_id'])\n",
    "\n",
    "train_dynamic_context = dynamic_context[dynamic_context['session'].isin(train_sessions)].reset_index(drop=True)\n",
    "test_dynamic_context = dynamic_context[dynamic_context['session'].isin(test_sessions)].reset_index(drop=True)\n",
    "train_static_context = static_context[static_context['session'].isin(train_sessions)].reset_index(drop=True)\n",
    "test_static_context = static_context[static_context['session'].isin(test_sessions)].reset_index(drop=True)\n",
    "train_dense_static_context = dense_static_context[dense_static_context['session'].isin(train_sessions)].reset_index(drop=True)\n",
    "test_dense_static_context = dense_static_context[dense_static_context['session'].isin(test_sessions)].reset_index(drop=True)\n",
    "\n",
    "print('number of session', len(train_dynamic_context.window_id.unique().tolist()), len(test_dynamic_context.window_id.unique().tolist()),\n",
    "       len(train_static_context.window_id.unique().tolist()), len(test_static_context.window_id.unique().tolist()),\n",
    "       len(train_dense_static_context.window_id.unique().tolist()), len(test_dense_static_context.window_id.unique().tolist()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_static_context.to_csv(f'{base_path}{augmentation_folder}static_context/unnormal/train.csv', index=False)\n",
    "test_static_context.to_csv(f'{base_path}{augmentation_folder}static_context/unnormal/test.csv', index=False)\n",
    "\n",
    "train_dynamic_context.to_csv(f'{base_path}{augmentation_folder}dynamic_context/unnormal/train.csv', index=False)\n",
    "test_dynamic_context.to_csv(f'{base_path}{augmentation_folder}dynamic_context/unnormal/test.csv', index=False)\n",
    "\n",
    "train_dense_static_context.to_csv(f'{base_path}{augmentation_folder}dense_static_context/unnormal/train.csv', index=False)\n",
    "test_dense_static_context.to_csv(f'{base_path}{augmentation_folder}dense_static_context/unnormal/test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dynamic_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for column in dense_static_context.columns:\n",
    "#     plt.figure(figsize=(8, 6))\n",
    "#     sns.histplot(dense_static_context[column], bins=20, color='skyblue', edgecolor='black', label='dense static', stat='percent')\n",
    "#     plt.title(f'Histogram of {column}')\n",
    "#     plt.xlabel(column)\n",
    "#     plt.ylabel('Percentage')\n",
    "#     plt.legend()\n",
    "#     plt.grid(True)\n",
    "#     plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Normalisation\n",
    "# dynamic_context_to_normalize = [col for col in train_dynamic_context.columns if col not in ['window_id', 'wind_id', 'session_ids', 'datetime', 'session_id', 'session']]\n",
    "# scaler_dynamic_context = RobustScaler(unit_variance=True)\n",
    "# scaler_dynamic_context.fit(train_dynamic_context[dynamic_context_to_normalize])\n",
    "# train_dc = scaler_dynamic_context.transform(train_dynamic_context[dynamic_context_to_normalize])\n",
    "# test_dc  = scaler_dynamic_context.transform(test_dynamic_context[dynamic_context_to_normalize])\n",
    "\n",
    "# scaler_dense_static_context = RobustScaler(unit_variance=True)\n",
    "# dense_static_context_to_normalize = [col for col in train_dense_static_context.columns if col not in ['window_id', 'wind_id', 'session_ids', 'datetime', 'session_id', 'session']]\n",
    "# scaler_dense_static_context.fit(train_dense_static_context[dense_static_context_to_normalize])\n",
    "# train_sdc = scaler_dense_static_context.transform(train_dense_static_context[dense_static_context_to_normalize])\n",
    "# test_sdc = scaler_dense_static_context.transform(test_dense_static_context[dense_static_context_to_normalize])\n",
    "\n",
    "# train_dc = pd.DataFrame(train_dc, columns=['avg_irradiation', 'steering_speed', 'temperature_out',\n",
    "#        'light_sensor_rear', 'light_sensor_front', 'temperature_in',\n",
    "#        'KBI_speed', 'latitude', 'longitude', 'altitude'])\n",
    "# test_dc = pd.DataFrame(test_dc, columns=['avg_irradiation', 'steering_speed', 'temperature_out',\n",
    "#        'light_sensor_rear', 'light_sensor_front', 'temperature_in',\n",
    "#        'KBI_speed', 'latitude', 'longitude', 'altitude'])\n",
    "# train_sdc = pd.DataFrame(train_sdc, columns=['distance_driven_benchmark', 'soc', 'time_second'])\n",
    "# test_sdc = pd.DataFrame(test_sdc, columns=['distance_driven_benchmark', 'soc', 'time_second'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for column in test_dc.columns:\n",
    "#     plt.figure(figsize=(8, 6))\n",
    "#     sns.histplot(test_dc[column], bins=20, color='skyblue', edgecolor='black', label='Test Data', stat='percent')\n",
    "#     sns.histplot(train_dc[column], bins=20, color='salmon', edgecolor='black', label='Train Data', stat='percent')\n",
    "#     plt.title(f'Histogram of {column}')\n",
    "#     plt.xlabel(column)\n",
    "#     plt.ylabel('Percentage')\n",
    "#     plt.legend()\n",
    "#     plt.grid(True)\n",
    "#     plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for column in test_sdc.columns:\n",
    "#     plt.figure(figsize=(8, 6))\n",
    "#     sns.histplot(test_sdc[column], bins=20, color='skyblue', edgecolor='black', label='Test Data', stat='percent')\n",
    "#     sns.histplot(train_sdc[column], bins=20, color='salmon', edgecolor='black', label='Train Data', stat='percent')\n",
    "#     plt.title(f'Histogram of {column}')\n",
    "#     plt.xlabel(column)\n",
    "#     plt.ylabel('Percentage')\n",
    "#     plt.legend()\n",
    "#     plt.grid(True)\n",
    "#     plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Normalisation\n",
    "# dynamic_context_to_normalize = [col for col in train_dynamic_context.columns if col not in ['window_id', 'wind_id', 'session_ids', 'datetime', 'session_id', 'session']]\n",
    "# scaler_dynamic_context = MinMaxScaler()\n",
    "# scaler_dynamic_context.fit(train_dynamic_context[dynamic_context_to_normalize])\n",
    "# train_dc = scaler_dynamic_context.transform(train_dynamic_context[dynamic_context_to_normalize])\n",
    "# test_dc  = scaler_dynamic_context.transform(test_dynamic_context[dynamic_context_to_normalize])\n",
    "\n",
    "# scaler_dense_static_context = MinMaxScaler()\n",
    "# dense_static_context_to_normalize = [col for col in train_dense_static_context.columns if col not in ['window_id', 'wind_id', 'session_ids', 'datetime', 'session_id', 'session']]\n",
    "# scaler_dense_static_context.fit(train_dense_static_context[dense_static_context_to_normalize])\n",
    "# train_sdc = scaler_dense_static_context.transform(train_dense_static_context[dense_static_context_to_normalize])\n",
    "# test_sdc = scaler_dense_static_context.transform(test_dense_static_context[dense_static_context_to_normalize])\n",
    "\n",
    "# train_dc = pd.DataFrame(train_dc, columns=['avg_irradiation', 'steering_speed', 'temperature_out',\n",
    "#        'light_sensor_rear', 'light_sensor_front', 'temperature_in',\n",
    "#        'KBI_speed', 'latitude', 'longitude', 'altitude'])\n",
    "# test_dc = pd.DataFrame(test_dc, columns=['avg_irradiation', 'steering_speed', 'temperature_out',\n",
    "#        'light_sensor_rear', 'light_sensor_front', 'temperature_in',\n",
    "#        'KBI_speed', 'latitude', 'longitude', 'altitude'])\n",
    "# train_sdc = pd.DataFrame(train_sdc, columns=['distance_driven_benchmark', 'soc', 'time_second'])\n",
    "# test_sdc = pd.DataFrame(test_sdc, columns=['distance_driven_benchmark', 'soc', 'time_second'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for column in test_dc.columns:\n",
    "#     plt.figure(figsize=(8, 6))\n",
    "#     sns.histplot(test_dc[column], bins=20, color='skyblue', edgecolor='black', label='Test Data', stat='percent')\n",
    "#     sns.histplot(train_dc[column], bins=20, color='salmon', edgecolor='black', label='Train Data', stat='percent')\n",
    "#     plt.title(f'Histogram of {column}')\n",
    "#     plt.xlabel(column)\n",
    "#     plt.ylabel('Percentage')\n",
    "#     plt.legend()\n",
    "#     plt.grid(True)\n",
    "#     plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for column in test_sdc.columns:\n",
    "#     plt.figure(figsize=(8, 6))\n",
    "#     sns.histplot(test_sdc[column], bins=20, color='skyblue', edgecolor='black', label='Test Data', stat='percent')\n",
    "#     sns.histplot(train_sdc[column], bins=20, color='salmon', edgecolor='black', label='Train Data', stat='percent')\n",
    "#     plt.title(f'Histogram of {column}')\n",
    "#     plt.xlabel(column)\n",
    "#     plt.ylabel('Percentage')\n",
    "#     plt.legend()\n",
    "#     plt.grid(True)\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Normalisation\n",
    "# dynamic_context_to_normalize = [col for col in train_dynamic_context.columns if col not in ['window_id', 'wind_id', 'session_ids', 'datetime', 'session_id', 'session']]\n",
    "# scaler_dynamic_context = StandardScaler()\n",
    "# scaler_dynamic_context.fit(train_dynamic_context[dynamic_context_to_normalize])\n",
    "# train_dc = scaler_dynamic_context.transform(train_dynamic_context[dynamic_context_to_normalize])\n",
    "# test_dc  = scaler_dynamic_context.transform(test_dynamic_context[dynamic_context_to_normalize])\n",
    "\n",
    "# scaler_dense_static_context = StandardScaler()\n",
    "# dense_static_context_to_normalize = [col for col in train_dense_static_context.columns if col not in ['window_id', 'wind_id', 'session_ids', 'datetime', 'session_id', 'session']]\n",
    "# scaler_dense_static_context.fit(train_dense_static_context[dense_static_context_to_normalize])\n",
    "# train_sdc = scaler_dense_static_context.transform(train_dense_static_context[dense_static_context_to_normalize])\n",
    "# test_sdc = scaler_dense_static_context.transform(test_dense_static_context[dense_static_context_to_normalize])\n",
    "\n",
    "# train_dc = pd.DataFrame(train_dc, columns=['avg_irradiation', 'steering_speed', 'temperature_out',\n",
    "#        'light_sensor_rear', 'light_sensor_front', 'temperature_in',\n",
    "#        'KBI_speed', 'latitude', 'longitude', 'altitude'])\n",
    "# test_dc = pd.DataFrame(test_dc, columns=['avg_irradiation', 'steering_speed', 'temperature_out',\n",
    "#        'light_sensor_rear', 'light_sensor_front', 'temperature_in',\n",
    "#        'KBI_speed', 'latitude', 'longitude', 'altitude'])\n",
    "# train_sdc = pd.DataFrame(train_sdc, columns=['distance_driven_benchmark', 'soc', 'time_second'])\n",
    "# test_sdc = pd.DataFrame(test_sdc, columns=['distance_driven_benchmark', 'soc', 'time_second'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for column in test_dc.columns:\n",
    "#     plt.figure(figsize=(8, 6))\n",
    "#     sns.histplot(test_dc[column], bins=20, color='skyblue', edgecolor='black', label='Test Data', stat='percent')\n",
    "#     sns.histplot(train_dc[column], bins=20, color='salmon', edgecolor='black', label='Train Data', stat='percent')\n",
    "#     plt.title(f'Histogram of {column}')\n",
    "#     plt.xlabel(column)\n",
    "#     plt.ylabel('Percentage')\n",
    "#     plt.legend()\n",
    "#     plt.grid(True)\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for column in test_sdc.columns:\n",
    "#     plt.figure(figsize=(8, 6))\n",
    "#     sns.histplot(test_sdc[column], bins=20, color='skyblue', edgecolor='black', label='Test Data', stat='percent')\n",
    "#     sns.histplot(train_sdc[column], bins=20, color='salmon', edgecolor='black', label='Train Data', stat='percent')\n",
    "#     plt.title(f'Histogram of {column}')\n",
    "#     plt.xlabel(column)\n",
    "#     plt.ylabel('Percentage')\n",
    "#     plt.legend()\n",
    "#     plt.grid(True)\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalisation\n",
    "dynamic_context_to_normalize = [col for col in train_dynamic_context.columns if col not in ['window_id', 'wind_id', 'session_ids', 'datetime', 'session_id', 'session']]\n",
    "scaler_dynamic_context = RobustScaler()\n",
    "scaler_dynamic_context.fit(train_dynamic_context[dynamic_context_to_normalize])\n",
    "train_dynamic_context[dynamic_context_to_normalize] = scaler_dynamic_context.transform(train_dynamic_context[dynamic_context_to_normalize])\n",
    "test_dynamic_context[dynamic_context_to_normalize] = scaler_dynamic_context.transform(test_dynamic_context[dynamic_context_to_normalize])\n",
    "\n",
    "#Robust scaler is used to account for the outlier in the data which make it non uniformly distributed\n",
    "scaler_dense_static_context = RobustScaler()\n",
    "scaler_dense_static_context.fit(train_dense_static_context[dense_static_context_var])\n",
    "train_dense_static_context[dense_static_context_var] = scaler_dense_static_context.transform(train_dense_static_context[dense_static_context_var])\n",
    "test_dense_static_context[dense_static_context_var] = scaler_dense_static_context.transform(test_dense_static_context[dense_static_context_var])\n",
    "\n",
    "train_dynamic_context.to_csv(train_dynamic_context_path, index=False)\n",
    "test_dynamic_context.to_csv(test_dynamic_context_path, index=False)\n",
    "\n",
    "train_static_context.to_csv(train_static_context_path, index=False)\n",
    "test_static_context.to_csv(test_static_context_path, index=False)\n",
    "\n",
    "train_dense_static_context.to_csv(train_dense_static_context_path, index=False)\n",
    "test_dense_static_context.to_csv(test_dense_static_context_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for column in train_dynamic_context.columns:\n",
    "#     print(column)\n",
    "#     plt.figure(figsize=(8, 6))\n",
    "#     sns.histplot(train_dynamic_context[column], bins=20, color='skyblue', edgecolor='black')\n",
    "#     plt.title(f'Histogram of {column}')\n",
    "#     plt.xlabel(column)\n",
    "#     plt.ylabel('Frequency')\n",
    "#     plt.grid(True) \n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dense_static_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_static_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dynamic_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_static_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dense_static_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dynamic_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def session_window_mapping(df):\n",
    "    session_window_dict = {}\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        session = int(row['session'])\n",
    "        window_id = int(row['window_id'])\n",
    "        \n",
    "        # If the session is not already in the dictionary, initialize an empty set\n",
    "        if session not in session_window_dict:\n",
    "            session_window_dict[session] = set()\n",
    "        \n",
    "        # Add the window_id to the set corresponding to the session\n",
    "        session_window_dict[session].add(window_id)\n",
    "\n",
    "    # Convert sets to lists in the resulting dictionary\n",
    "    session_window_dict = {session: list(window_ids) for session, window_ids in session_window_dict.items()}\n",
    "    return session_window_dict\n",
    "\n",
    "train_session_win_id_mapping_dc = session_window_mapping(train_dynamic_context)\n",
    "test_session_win_id_mapping_dc = session_window_mapping(test_dynamic_context)\n",
    "train_session_win_id_mapping_sc = session_window_mapping(train_static_context)\n",
    "test_session_win_id_mapping_sc = session_window_mapping(test_static_context)\n",
    "train_session_win_id_mapping_dsc = session_window_mapping(train_dense_static_context)\n",
    "test_session_win_id_mapping_dsc = session_window_mapping(test_dense_static_context)\n",
    "\n",
    "with open(os.path.join(parameter_path, 'session_win_id_mapping.pkl'), 'rb') as pickle_file:\n",
    "    train_session_win_id_mapping = pickle.load(pickle_file)\n",
    "    test_session_win_id_mapping = pickle.load(pickle_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(train_session_win_id_mapping_dc), len(train_session_win_id_mapping_sc),  len(train_session_win_id_mapping_dsc), len(train_session_win_id_mapping))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if train_session_win_id_mapping_dc == train_session_win_id_mapping_sc == train_session_win_id_mapping == train_session_win_id_mapping_dsc:\n",
    "    print(\"All training data mapping are exactly identical.\")\n",
    "if test_session_win_id_mapping_dc == test_session_win_id_mapping_sc == test_session_win_id_mapping == test_session_win_id_mapping_dsc:\n",
    "    print(\"All testing data mapping are exactly identical.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(train_dynamic_context.session.unique().tolist()), len(test_dynamic_context.session.unique().tolist()))\n",
    "print(len(train_dynamic_context.window_id.unique().tolist()), len(test_dynamic_context.window_id.unique().tolist()))\n",
    "print(len(train_static_context.session.unique().tolist()), len(test_static_context.session.unique().tolist()))\n",
    "print(len(train_static_context.window_id.unique().tolist()), len(test_static_context.window_id.unique().tolist()))\n",
    "print(len(train_dense_static_context.session.unique().tolist()), len(test_dense_static_context.session.unique().tolist()))\n",
    "print(len(train_dense_static_context.window_id.unique().tolist()), len(test_dense_static_context.window_id.unique().tolist()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "carsii",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
