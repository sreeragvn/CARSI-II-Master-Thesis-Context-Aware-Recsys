{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TO_LOAD = '../data/04_Merged'\n",
    "\n",
    "merge_context_data = True\n",
    "regenerate_context_data = True\n",
    "sequence_augmentation = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_columns = ['index', 'avg_irradiation', 'steering_speed', 'temperature_out', 'hour',\n",
    "       'month', 'odometer', 'light_sensor_rear', 'light_sensor_front',\n",
    "       'temperature_in', 'KBI_speed', 'soc', 'ESP_speed', 'latitude',\n",
    "       'longitude', 'seatbelt_codriver', 'seatbelt_rear_l', 'seatbelt_rear_m',\n",
    "       'seatbelt_rear_r', 'CHA_ESP_drive_mode', 'CHA_MO_drive_mode',\n",
    "       'rain_sensor', 'street_category', 'kickdown', 'altitude',\n",
    "       'driving_program', 'datetime', 'session', 'Label', 'ID',\n",
    "       'FunctionValue', 'domain', 'BeginTime', 'time_second',\n",
    "       'distance_driven', 'ts_normalized', 'weekday']\n",
    "\n",
    "selected = [ 'avg_irradiation', 'steering_speed', 'temperature_out', 'hour',\n",
    "       'month', 'light_sensor_rear', 'light_sensor_front',\n",
    "       'temperature_in', 'KBI_speed', 'soc', 'latitude',\n",
    "       'longitude', 'seatbelt_codriver', 'seatbelt_rear_l',\n",
    "       'seatbelt_rear_r', 'street_category', 'altitude',\n",
    "       'datetime', 'session', 'time_second',\n",
    "       'distance_driven', 'weekday'\n",
    "]\n",
    "\n",
    "bad_quality = ['CHA_ESP_drive_mode', \n",
    "             'CHA_MO_drive_mode',\n",
    "             'rain_sensor',\n",
    "             'kickdown',\n",
    "             'ESP_speed',\n",
    "             'seatbelt_rear_m',\n",
    "            'driving_program',\n",
    "            'ts_normalized'\n",
    "             ]\n",
    "\n",
    "dynamic_context_var = ['avg_irradiation', 'steering_speed', 'temperature_out', 'hour',\n",
    "                       'light_sensor_rear', 'light_sensor_front', \n",
    "                       'temperature_in', 'KBI_speed', 'soc', 'latitude',\n",
    "                       'longitude', 'seatbelt_codriver', 'seatbelt_rear_l',\n",
    "                       'seatbelt_rear_r', 'street_category', 'altitude','time_second',\n",
    "                       'distance_driven']\n",
    "static_context_var = ['car_id', 'month', 'weekday']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# var = 'hour'\n",
    "# test_min = {}\n",
    "# test_max = {}\n",
    "# for session in df.session.unique().tolist():\n",
    "#     df_curr = df[df['session']==session]\n",
    "#     test_min[session] = df_curr[var].min()\n",
    "#     test_max[session] = df_curr[var].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## create context data\n",
    "\n",
    "def load_context(vehicle):\n",
    "    df = pd.read_csv(os.path.join(PATH_TO_LOAD, vehicle + \"_merged.csv\"), parse_dates=['datetime'], low_memory=False)\n",
    "    context_lists = dynamic_context_var + static_context_var + ['session', 'datetime']\n",
    "    context_lists.remove('car_id')\n",
    "    df_filt = df[context_lists]\n",
    "    df_filt = df_filt.dropna(subset=['KBI_speed'])\n",
    "    df_filt_sort = df_filt.sort_values(by=['session','datetime'])\n",
    "    return df_filt_sort\n",
    "\n",
    "vehicles = ['SEB880','SEB882','SEB883','SEB885','SEB888','SEB889']\n",
    "context_data = pd.DataFrame()\n",
    "\n",
    "if merge_context_data == True:\n",
    "    for vehicle in tqdm(vehicles):\n",
    "        context_curr = load_context(vehicle)\n",
    "        context_curr['car_id'] = vehicle\n",
    "        context_data = pd.concat([context_data, context_curr], axis=0)\n",
    "    context_data.to_csv('../data/05_Interaction_Sequences/context.csv')\n",
    "\n",
    "if regenerate_context_data == True:\n",
    "    # selected_sessions = merged_df['session'].unique().tolist()\n",
    "\n",
    "    context_data = pd.read_csv('../data/05_Interaction_Sequences/context.csv', parse_dates=['datetime'], index_col=0)\n",
    "    \n",
    "    vehicle_list = context_data.car_id.unique().tolist()\n",
    "    vehicle_dict = {vehicle: random.randint(1, 50) for vehicle in vehicle_list}\n",
    "    context_data['car_id'] = context_data['car_id'].map(vehicle_dict)\n",
    "    context_data = context_data.sort_values(by=['session','datetime'])\n",
    "    context_data['session'] = context_data['session'].astype(int)\n",
    "    static_context_var.append('session')\n",
    "    static_context = context_data[static_context_var].drop_duplicates(subset=['car_id', 'session'])\n",
    "    # context_data = context_data[dynamic_context]\n",
    "    # selected_context = ['KBI_speed', 'car_id']\n",
    "    dynamic_context_var.extend(['session', 'datetime'])\n",
    "    dynamic_context = context_data[dynamic_context_var]\n",
    "    dynamic_context_var = [item for item in dynamic_context_var if item not in ['session', 'datetime']]\n",
    "    dynamic_context = dynamic_context.groupby(['session', 'datetime'])[dynamic_context_var].mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_sequence = pd.read_csv('../data/05_Interaction_Sequences/sequence_context.csv', parse_dates=['datetime'], index_col=0).reset_index()\n",
    "selected_sequence['session'] = selected_sequence['session'].astype(int)\n",
    "\n",
    "temp_df = selected_sequence.groupby('session').apply(lambda group: group.iloc[:-1]).reset_index(drop=True)\n",
    "dynamic_context = dynamic_context[dynamic_context['session'].isin(temp_df.session.unique().tolist())]\n",
    "\n",
    "training_sequence_context = pd.DataFrame()\n",
    "for session in tqdm(selected_sequence['session'].unique().tolist()):\n",
    "    selected_sequence_curr = selected_sequence[selected_sequence['session']==session]\n",
    "    context_data_curr = dynamic_context[dynamic_context['session']==session]\n",
    "    context_data_curr = context_data_curr[context_data_curr['datetime']<=selected_sequence_curr['datetime'].max()]\n",
    "    training_sequence_context = pd.concat([training_sequence_context,context_data_curr], axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing_sessions = [16, 25]\n",
    "# selected_sequence = selected_sequence[selected_sequence['session'].isin(testing_sessions)]\n",
    "# training_sequence_context = training_sequence_context[training_sequence_context['session'].isin(testing_sessions)]\n",
    "\n",
    "training_sequence_context_augmented = pd.DataFrame()\n",
    "session_id = 0\n",
    "if sequence_augmentation == True:\n",
    "    for session in tqdm(selected_sequence['session'].unique().tolist()):\n",
    "        selected_sequence_curr = selected_sequence[selected_sequence['session']==session].reset_index()\n",
    "        context_curr = training_sequence_context[training_sequence_context['session']==session].reset_index()\n",
    "        for i in range(len(selected_sequence_curr)-1, -1, -1):\n",
    "            context_filt_curr = training_sequence_context[\n",
    "                (training_sequence_context['datetime'] <= selected_sequence_curr.loc[i, 'datetime'])].copy()\n",
    "            # context_filt_curr.loc[context_filt_curr.index, 'session_id'] = session_id\n",
    "            context_filt_curr['session_id'] = session_id\n",
    "            training_sequence_context_augmented = pd.concat([training_sequence_context_augmented, context_filt_curr], axis=0)\n",
    "            session_id += 1\n",
    "    dynamic_context = training_sequence_context_augmented\n",
    "else:\n",
    "    # if sequence_augmentation is set to false\n",
    "    dynamic_context = training_sequence_context\n",
    "\n",
    "\n",
    "with open('../data/05_Interaction_Sequences/train_sessions.pkl', 'rb') as pickle_file:\n",
    "    train_sessions = pickle.load(pickle_file)\n",
    "\n",
    "with open('../data/05_Interaction_Sequences/test_sessions.pkl', 'rb') as pickle_file:\n",
    "    test_sessions = pickle.load(pickle_file)\n",
    "\n",
    "train_context_data = dynamic_context[dynamic_context['session'].isin(train_sessions)]\n",
    "test_context_data = dynamic_context[dynamic_context['session'].isin(test_sessions)]\n",
    "\n",
    "train_static_context = static_context[static_context['session'].isin(train_sessions)]\n",
    "test_static_context = static_context[static_context['session'].isin(test_sessions)]\n",
    "\n",
    "train_static_context['session'] = range(len(train_static_context))\n",
    "test_static_context['session'] = range(len(test_static_context))\n",
    "\n",
    "train_context_data['session'] = train_context_data.groupby('session').ngroup()\n",
    "test_context_data['session'] = test_context_data.groupby('session').ngroup()\n",
    "\n",
    "train_context_data = train_context_data.rename(columns={'session': 'session_id'})\n",
    "test_context_data = test_context_data.rename(columns={'session': 'session_id',})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalization of data\n",
    "# train_static_context = train_static_context.round(2)\n",
    "# test_static_context = test_static_context.round(2)\n",
    "# train_context_data = train_context_data.round(2)\n",
    "# test_context_data = test_context_data.round(2)\n",
    "\n",
    "dynamic_context_to_normalize = [col for col in train_context_data.columns if col not in ['session_id', 'datetime']]\n",
    "scaler_dynamic_context = MinMaxScaler()\n",
    "scaler_dynamic_context.fit(train_context_data[dynamic_context_to_normalize])\n",
    "train_context_data[dynamic_context_to_normalize] = scaler_dynamic_context.transform(train_context_data[dynamic_context_to_normalize])\n",
    "test_context_data[dynamic_context_to_normalize] = scaler_dynamic_context.transform(test_context_data[dynamic_context_to_normalize])\n",
    "\n",
    "\n",
    "static_context_to_normalize = [col for col in train_static_context.columns if col not in ['session']]\n",
    "scaler_static_context = MinMaxScaler()\n",
    "scaler_static_context.fit(train_static_context[static_context_to_normalize])\n",
    "train_static_context[static_context_to_normalize] = scaler_static_context.transform(train_static_context[static_context_to_normalize])\n",
    "test_static_context[static_context_to_normalize] = scaler_static_context.transform(test_static_context[static_context_to_normalize])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_context_data.to_csv('../datasets/sequential/carsii_timedelta_rand_seq/dynamic_context/train.csv', index=False)\n",
    "test_context_data.to_csv('../datasets/sequential/carsii_timedelta_rand_seq/dynamic_context/test.csv', index=False)\n",
    "\n",
    "train_static_context.to_csv('../datasets/sequential/carsii_timedelta_rand_seq/static_context/train.csv', index=False)\n",
    "test_static_context.to_csv('../datasets/sequential/carsii_timedelta_rand_seq/static_context/test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_context_data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "carsii",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
