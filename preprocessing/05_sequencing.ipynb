{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<frozen importlib._bootstrap>:219: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import re\n",
    "import json\n",
    "import concurrent.futures\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import pickle "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TO_LOAD = '../data/04_Merged'\n",
    "sequence_augmentation = False\n",
    "text_num_mapping_start = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:33<00:00,  5.60s/it]\n"
     ]
    }
   ],
   "source": [
    "# def load_df(vehicle):\n",
    "#     df = pd.read_csv(os.path.join(PATH_TO_LOAD, vehicle + \"_merged.csv\"), parse_dates=['datetime'], low_memory=False, index_col=0)\n",
    "#     df = df.dropna(subset=['Label'])\n",
    "#     df = df.sort_values(by=['session','datetime'])\n",
    "#     df['full_label'] = df['Label'] + ' ' + df['FunctionValue']\n",
    "#     return df\n",
    "\n",
    "def load_df(vehicle):\n",
    "    df = pd.read_csv(os.path.join(PATH_TO_LOAD, vehicle + \"_merged.csv\"), parse_dates=['datetime'], low_memory=False, index_col=0)\n",
    "    df = df.dropna(subset=['Label'])\n",
    "    df = df.sort_values(by=['session', 'datetime'])\n",
    "    mask = df['Label'] == 'navi/Start/Address'\n",
    "    df.loc[mask, 'FunctionValue'] = 'a'\n",
    "    df['full_label'] = df['Label'] + ' ' + df['FunctionValue']\n",
    "    return df\n",
    "\n",
    "full_df = pd.DataFrame()\n",
    "\n",
    "vehicles = ['SEB880','SEB882','SEB883','SEB885','SEB888','SEB889']\n",
    "# for vehicle in tqdm(vehicles):\n",
    "#     df_curr = load_df(vehicle)\n",
    "#     df_curr['vehicle'] = vehicle\n",
    "#     df_curr = df_curr.dropna(subset=['full_label'])\n",
    "#     full_df = pd.concat([full_df, df_curr], ignore_index=True)\n",
    "\n",
    "def process_vehicle(vehicle):\n",
    "    df_curr = load_df(vehicle)\n",
    "    df_curr['vehicle'] = vehicle\n",
    "    df_curr = df_curr.dropna(subset=['full_label'])\n",
    "    return df_curr\n",
    "\n",
    "with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "    results = list(tqdm(executor.map(process_vehicle, vehicles), total=len(vehicles)))\n",
    "\n",
    "full_df = pd.concat(results, ignore_index=True)\n",
    "\n",
    "mapping = {category: index + text_num_mapping_start for index, category in enumerate(full_df['full_label'].unique())}\n",
    "full_df['full_label_num'] = full_df['full_label'].replace(mapping)\n",
    "\n",
    "mapping_vehicle = {category: index + text_num_mapping_start for index, category in enumerate(full_df['vehicle'].unique())}\n",
    "full_df['vehicle_num'] = full_df['vehicle'].replace(mapping_vehicle)\n",
    "\n",
    "filt_df = full_df[['session','full_label_num','vehicle_num', 'datetime']].sort_values(by = ['session', 'datetime'])\n",
    "filt_df = filt_df.drop_duplicates()\n",
    "\n",
    "filt_df['interaction_time_delta'] = (filt_df.groupby('session')['datetime'].diff().dt.total_seconds()/60).round(1)\n",
    "filt_df['interaction_time_delta'] = filt_df['interaction_time_delta'].fillna(0)\n",
    "filt_df['interaction_time_delta'] = filt_df['interaction_time_delta'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session</th>\n",
       "      <th>full_label_num</th>\n",
       "      <th>vehicle_num</th>\n",
       "      <th>datetime</th>\n",
       "      <th>interaction_time_delta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2022-09-07 21:00:51</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>20.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2022-09-10 17:15:06</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>27.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2022-09-11 12:26:02</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>45.0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2022-09-16 07:13:03</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>46.0</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>2022-09-16 11:36:04</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6128</th>\n",
       "      <td>5373.0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>2023-03-25 15:20:25</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6129</th>\n",
       "      <td>5375.0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>2023-03-26 08:29:12</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6131</th>\n",
       "      <td>5384.0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>2023-03-28 08:10:54</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6132</th>\n",
       "      <td>5385.0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>2023-03-28 09:06:58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6134</th>\n",
       "      <td>5386.0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>2023-03-28 10:10:12</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>432 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      session  full_label_num  vehicle_num            datetime  \\\n",
       "0         7.0               2            2 2022-09-07 21:00:51   \n",
       "6        20.0               3            2 2022-09-10 17:15:06   \n",
       "10       27.0               2            2 2022-09-11 12:26:02   \n",
       "19       45.0               5            2 2022-09-16 07:13:03   \n",
       "20       46.0               7            2 2022-09-16 11:36:04   \n",
       "...       ...             ...          ...                 ...   \n",
       "6128   5373.0               3            7 2023-03-25 15:20:25   \n",
       "6129   5375.0               3            7 2023-03-26 08:29:12   \n",
       "6131   5384.0               3            7 2023-03-28 08:10:54   \n",
       "6132   5385.0               3            7 2023-03-28 09:06:58   \n",
       "6134   5386.0               3            7 2023-03-28 10:10:12   \n",
       "\n",
       "      interaction_time_delta  \n",
       "0                          0  \n",
       "6                          0  \n",
       "10                         0  \n",
       "19                         0  \n",
       "20                         0  \n",
       "...                      ...  \n",
       "6128                       0  \n",
       "6129                       0  \n",
       "6131                       0  \n",
       "6132                       0  \n",
       "6134                       0  \n",
       "\n",
       "[432 rows x 5 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To do add those session with just one interactions. that one interaction can the target and input sequence can be no click along with the context\n",
    "# find session with just one interactions\n",
    "session_counts = filt_df['session'].value_counts()\n",
    "session_with_one_interactions = session_counts[session_counts == 1].index.tolist()\n",
    "one_interactions = filt_df[filt_df['session'].isin(session_with_one_interactions)]\n",
    "one_interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "relevanat_df = filt_df[~filt_df['session'].isin(session_with_one_interactions)]\n",
    "len(relevanat_df.session.unique().tolist())\n",
    "relevanat_df[['session', 'datetime']].to_csv('../data/05_Interaction_Sequences/sequence_context.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Generating augmented data\n",
    "def explode_both(row):\n",
    "        sequences = row['sequence']\n",
    "        time_deltas = row['time_delta']\n",
    "        sessions = [row['session']] * len(sequences)\n",
    "        return pd.DataFrame({'session': sessions, 'sequence': sequences, 'time_delta': time_deltas})\n",
    "\n",
    "def sequence_generation(df, sequence_augmentation):\n",
    "    sequence_dict = {\n",
    "        'session': [],\n",
    "        'sequence': [],\n",
    "        'time_delta': []\n",
    "    }\n",
    "    if sequence_augmentation == True:\n",
    "        for session in df['session'].unique().tolist():\n",
    "            check_df = df[df['session']== session]\n",
    "\n",
    "            sequence_list = []\n",
    "            time_delta_list = []\n",
    "            seq_length = len(check_df)\n",
    "            sequence = check_df['full_label_num'].tolist()\n",
    "            time_delta = check_df['interaction_time_delta'].tolist()\n",
    "            # print(session)\n",
    "            # print(seq_length)\n",
    "            # print(sequence)\n",
    "            # print(time_delta)\n",
    "            while seq_length != 1:\n",
    "                sequence_list.append(sequence)\n",
    "                time_delta_list.append(time_delta)\n",
    "                # print(sequence_list)\n",
    "                # print(time_delta_list)\n",
    "                time_delta = time_delta[:-1]\n",
    "                sequence = sequence[:-1]\n",
    "                seq_length = seq_length -1\n",
    "            sequence_dict['session'].append(session)\n",
    "            sequence_dict['sequence'].append(sequence_list)\n",
    "            sequence_dict['time_delta'].append(time_delta_list)\n",
    "        sequence_df = pd.DataFrame(sequence_dict)\n",
    "        sequence_df = pd.concat(sequence_df.apply(explode_both, axis=1).tolist(), ignore_index=True)\n",
    "    else:\n",
    "        for session in df['session'].unique().tolist():\n",
    "            check_df = df[df['session']== session]\n",
    "            \n",
    "            if len(check_df) == 1:\n",
    "                 continue\n",
    "            sequence_list = []\n",
    "            time_delta_list = []\n",
    "            seq_length = len(check_df)\n",
    "            sequence = check_df['full_label_num'].tolist()\n",
    "            time_delta = check_df['interaction_time_delta'].tolist()\n",
    "            \n",
    "            sequence_dict['session'].append(session)\n",
    "            sequence_dict['sequence'].append(sequence)\n",
    "            sequence_dict['time_delta'].append(time_delta)\n",
    "        sequence_df = pd.DataFrame(sequence_dict)\n",
    "\n",
    "    return sequence_df\n",
    "\n",
    "test_df = test_df = filt_df.drop(columns=['datetime', 'vehicle_num'])\n",
    "df_exploded = sequence_generation(test_df, sequence_augmentation)\n",
    "\n",
    "df_exploded['time_delta_list'] = df_exploded['time_delta'].apply(lambda x: x[1:] if isinstance(x, list) and len(x) > 1 else x)\n",
    "df_exploded['interaction_time_delta_train'] = df_exploded['time_delta_list'].apply(lambda x: ' '.join(map(str, x)) if isinstance(x, list) else x)\n",
    "df_exploded['item_id_seq_train'] = df_exploded['sequence'].apply(lambda x: ' '.join(map(str, x[:-1])) if isinstance(x, list) and len(x) > 1 else None)\n",
    "df_exploded['item_id_target'] = df_exploded['sequence'].apply(lambda x: x[-1] if isinstance(x, list) and len(x) > 0 else None)\n",
    "df_exploded = df_exploded.dropna(subset=['item_id_target'])\n",
    "df_exploded['item_id_target'] = df_exploded['item_id_target'].astype(int)\n",
    "df_exploded = df_exploded.drop(columns=['sequence', 'time_delta', 'time_delta_list'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 7,\n",
       " 8,\n",
       " 9,\n",
       " 11,\n",
       " 12,\n",
       " 14,\n",
       " 16,\n",
       " 17,\n",
       " 18,\n",
       " 19,\n",
       " 20,\n",
       " 22,\n",
       " 23,\n",
       " 24,\n",
       " 25,\n",
       " 26,\n",
       " 27,\n",
       " 30,\n",
       " 31,\n",
       " 32,\n",
       " 34,\n",
       " 35,\n",
       " 36,\n",
       " 37,\n",
       " 38,\n",
       " 39,\n",
       " 41,\n",
       " 46,\n",
       " 48,\n",
       " 50]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(df_exploded.item_id_target.unique().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "if sequence_augmentation == True:\n",
    "      total_sessions = df_exploded.session.unique().tolist()\n",
    "      test_sessions, train_sessions = train_test_split(total_sessions, test_size=0.8, shuffle=True, random_state=42)\n",
    "      train_df = df_exploded[df_exploded['session'].isin(train_sessions)].sort_index()\n",
    "      test_df = df_exploded[df_exploded['session'].isin(test_sessions)].sort_index()\n",
    "else:\n",
    "      train_df, test_df = train_test_split(df_exploded, test_size=0.2, shuffle=True, random_state=42)\n",
    "      train_df = train_df.sort_index()\n",
    "      test_df = test_df.sort_index()\n",
    "      train_sessions = train_df['session'].unique().tolist()\n",
    "      test_sessions = test_df['session'].unique().tolist()\n",
    "\n",
    "with open('../data/05_Interaction_Sequences/train_sessions.pkl', 'wb') as pickle_file:\n",
    "        pickle.dump(train_sessions, pickle_file)\n",
    "\n",
    "with open('../data/05_Interaction_Sequences/test_sessions.pkl', 'wb') as pickle_file:\n",
    "        pickle.dump(test_sessions, pickle_file)\n",
    "\n",
    "# train_df = train_df.sort_values(by='session')\n",
    "# test_df = test_df.sort_values(by='session')\n",
    "\n",
    "train_df = train_df.drop(['session'], axis=1)\n",
    "test_df = test_df.drop(['session'], axis=1)\n",
    "\n",
    "test_df['session_id'] = range(len(test_df))\n",
    "test_df['session_id'] = test_df['session_id'].astype(int)\n",
    "\n",
    "train_df['session_id'] = range(len(train_df))\n",
    "train_df['session_id'] = train_df['session_id'].astype(int)\n",
    "\n",
    "train_df = train_df[['session_id', 'item_id_seq_train', 'item_id_target', 'interaction_time_delta_train']]\n",
    "test_df = test_df[['session_id', 'item_id_seq_train', 'item_id_target', 'interaction_time_delta_train']]\n",
    "\n",
    "if sequence_augmentation == True:\n",
    "    test_df.to_csv('../datasets/sequential/aug/seq/test.tsv', sep='\\t', index=False)\n",
    "    train_df.to_csv('../datasets/sequential/aug/seq/train.tsv', sep='\\t', index=False)\n",
    "else:\n",
    "    test_df.to_csv('../datasets/sequential/non_aug/seq/test.tsv', sep='\\t', index=False)\n",
    "    train_df.to_csv('../datasets/sequential/non_aug/seq/train.tsv', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([8.3262e-10, 8.3262e-10, 1.0588e-02, 1.9251e-04, 7.0588e-03, 6.3529e-03,\n",
       "        3.7370e-04, 5.9933e-04, 6.3529e-02, 1.0588e-02, 8.3262e-10, 8.3262e-10,\n",
       "        2.1176e-02, 8.3262e-10, 3.1764e-02, 8.3262e-10, 6.3529e-02, 6.3529e-02,\n",
       "        3.1764e-02, 7.9411e-03, 2.6470e-03, 8.3262e-10, 1.0588e-02, 6.3529e-02,\n",
       "        6.3529e-02, 6.3529e-02, 1.0588e-02, 1.5882e-02, 8.3262e-10, 8.3262e-10,\n",
       "        6.3529e-02, 3.1764e-02, 3.9706e-03, 8.3262e-10, 2.1176e-02, 2.1176e-02,\n",
       "        6.3529e-02, 2.0493e-03, 2.1176e-02, 6.3529e-02, 8.3262e-10, 8.3262e-10,\n",
       "        8.3262e-10, 8.3262e-10, 8.3262e-10, 8.3262e-10, 3.1764e-02, 8.3262e-10,\n",
       "        6.3529e-02, 8.3262e-10, 6.3529e-02])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = '../datasets/sequential/non_aug/seq/train.tsv'\n",
    "train_data = pd.read_csv(file_path, sep='\\t')\n",
    "\n",
    "def compute_class_weights(data):\n",
    "    labels = torch.tensor(data.item_id_target)\n",
    "    class_count = torch.bincount(labels)\n",
    "    total_samples = len(labels)\n",
    "    epsilon = 1e-5\n",
    "    class_weights = 1.0 / ((class_count.float()) / total_samples)\n",
    "    small_value = 1e-5\n",
    "    class_weights[torch.isinf(class_weights)] = small_value\n",
    "    # class_weights = torch.where(torch.isinf(class_weights), torch.tensor(0.0), class_weights)\n",
    "    sum_weights = torch.sum(class_weights)\n",
    "    class_weights = class_weights / sum_weights\n",
    "    return class_weights\n",
    "\n",
    "class_weights = compute_class_weights(train_data)\n",
    "\n",
    "with open('../datasets/sequential/non_aug/param.pkl', 'wb') as f:\n",
    "        pickle.dump(class_weights, f)\n",
    "\n",
    "class_weights"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "carsii",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
