{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<frozen importlib._bootstrap>:219: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import re\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import pickle\n",
    "\n",
    "PATH_TO_LOAD = '../data/04_Merged'\n",
    "vehicle = 'SEB889'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "session_dict_generation = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_df(vehicle):\n",
    "    df = pd.read_csv(os.path.join(PATH_TO_LOAD, vehicle + \"_merged.csv\"), parse_dates=['datetime'], low_memory=False)\n",
    "    df_filt = df.drop(['index', 'avg_irradiation', 'steering_speed', 'temperature_out', 'hour',\n",
    "                        'month', 'odometer', 'light_sensor_rear', 'light_sensor_front',\n",
    "                        'temperature_in', 'KBI_speed', 'soc', 'ESP_speed', 'latitude',\n",
    "                        'longitude', 'seatbelt_codriver', 'seatbelt_rear_l', 'seatbelt_rear_m',\n",
    "                        'seatbelt_rear_r', \n",
    "                        'rain_sensor', 'street_category', 'kickdown', 'altitude',\n",
    "                        'driving_program', 'CHA_MO_drive_mode',\n",
    "                        'distance_driven', 'ts_normalized', 'weekday', 'CHA_ESP_drive_mode'], axis=1, inplace=False)\n",
    "    df_filt = df_filt.dropna(subset=['Label'])\n",
    "    df_filt_sort = df_filt.sort_values(by=['session','datetime'])\n",
    "    return df_filt_sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "drive_mode_mapping = {\n",
    "    '0.0': 'Normal',\n",
    "    '1.0': 'Sport',\n",
    "    '2.0': 'Super Sport',\n",
    "    '3.0': 'Range',\n",
    "    '4.0': 'Gravel / Offroad'\n",
    "}\n",
    "\n",
    "climate_label = {\n",
    "    'clima': 'climate',\n",
    "    'AC': 'air conditioning'\n",
    "}\n",
    "\n",
    "def replace_label(label):\n",
    "    match = re.search(r'\\d+\\.\\d+', label)\n",
    "    if match:\n",
    "        numeric_part = match.group()\n",
    "        replacement = drive_mode_mapping.get(numeric_part, numeric_part)\n",
    "        return label.replace(numeric_part, replacement)\n",
    "    else:\n",
    "        return label\n",
    "    \n",
    "def custom_concat(row):\n",
    "    # Check if the \"Label\" column value is \"media/selectedSource/Bluetooth\"\n",
    "    if row['Label'] == 'media/selectedSource/Bluetooth':\n",
    "        return f\"{row['Label']}:{row['FunctionValue']}\"\n",
    "    else:\n",
    "        return row['Label']\n",
    "\n",
    "def remove_consecutive_duplicates(row):\n",
    "    words = row.split()  # Split the row into words\n",
    "    unique_words = [words[0]]  # Initialize a list with the first word\n",
    "\n",
    "    # Iterate through the words and add non-consecutive duplicates to the list\n",
    "    for word in words[1:]:\n",
    "        if word != unique_words[-1]:\n",
    "            unique_words.append(word)\n",
    "\n",
    "    return ' '.join(unique_words) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def itemization(df):\n",
    "    # Apply the function to the \"Label\" column\n",
    "    \n",
    "    df['Label'] = df['Label'].apply(replace_label)\n",
    "    df['Label'] = df['Label'].replace(climate_label)\n",
    "    df['Label'] = df['Label'].replace({'car/ESS/on' : '/car/eSoundSystem/on'})\n",
    "    df['Label'] = df['Label'].replace({'clima/AC/off' : 'climate/AirConditioning/off'})\n",
    "    df['Label'] = df['Label'].replace({'clima/AC/on' : 'climate/AirConditioning/on'})\n",
    "    df['Label'] = df['Label'].replace({'clima/AC/ECO' : 'climate/AirConditioning/ECO'})\n",
    "    df['Label'] = df.apply(custom_concat, axis=1)\n",
    "    condition = df['FunctionValue'] == 'Bluetooth::BLUETOOTH'\n",
    "    df['Label'] = df['Label'].str.replace('ðŸ¦–', '')\n",
    "    df['Label'] = df['Label'].str.replace('car/driveMode/0', 'car/driveMode/Normal')\n",
    "    df['Label'] = df['Label'].str.replace('car/driveMode/2', 'car/driveMode/Super Sport')\n",
    "    df['Label'] = df['Label'].str.replace('car/driveMode/3', 'car/driveMode/Range')\n",
    "    df['Label'] = df['Label'].apply(remove_consecutive_duplicates)\n",
    "    df['Label'] = df['Label'].str.replace('media/selectedSource/Favorite', \n",
    "                                                            'media/selectedSource/Favorite:TUNER_FAVORITES')\n",
    "    df['Label'] = df['Label'].str.replace('media/selectedSource/CarPlay', \n",
    "                                                            'media/selectedSource/Apple CarPlay')\n",
    "    df['Label'] = df['Label'].str.replace('phone/Start/CarPlay', \n",
    "                                                            'phone/Start/Apple CarPlay')\n",
    "    df.loc[condition, 'Label'] = \"media/selectedSource/Bluetooth\"\n",
    "    df['Label'] = df['Label'].str.replace('media/selectedSource/Bluetooth:Bluetooth::BLUETOOTH',\n",
    "                                                            'media/selectedSource/Bluetooth')\n",
    "\n",
    "\n",
    "    # Display the updated DataFrame\n",
    "    return df\n",
    "\n",
    "if session_dict_generation == True:\n",
    "    actions = []\n",
    "    combined_df = pd.DataFrame()\n",
    "    vehicles = ['SEB880','SEB882','SEB883','SEB885','SEB888','SEB889']\n",
    "    for vehicle in tqdm(vehicles):\n",
    "        df_filt_sort = load_df(vehicle)\n",
    "        df_filt_sort['vehicle'] = vehicle\n",
    "        processed_df = itemization(df_filt_sort)\n",
    "        actions.append(processed_df['Label'].unique().tolist())\n",
    "        combined_df = pd.concat([combined_df, processed_df], ignore_index=True)#\n",
    "\n",
    "    actions_unique = sorted(list(set([item for sublist in actions for item in sublist])))\n",
    "    actions_unique_dict = {element: random.randint(1, 120) for element in actions_unique}\n",
    "    combined_df.to_csv(\"../data/05_Interaction_Sequences/01_vehicles_merged.csv\")\n",
    "\n",
    "    with open('../data/05_Interaction_Sequences/infotainment_interaction_dict.pkl', 'wb') as pickle_file:\n",
    "        pickle.dump(actions_unique_dict, pickle_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/05_Interaction_Sequences/infotainment_interaction_dict.pkl', 'rb') as pickle_file:\n",
    "    actions_unique_dict = pickle.load(pickle_file)\n",
    "\n",
    "combined_df = pd.read_csv(\"../data/05_Interaction_Sequences/01_vehicles_merged.csv\", index_col=0)\n",
    "combined_df = combined_df[['session','Label','vehicle']]\n",
    "combined_df['Label_tokens'] = combined_df['Label'].map(actions_unique_dict)\n",
    "serialized_df = combined_df.groupby('session')['Label_tokens'].agg(lambda x: ' '.join(map(str, x))).reset_index()\n",
    "session_vehicle_dict = dict(zip(combined_df['session'], combined_df['vehicle']))\n",
    "\n",
    "serialized_df['Label_tokens_list'] = serialized_df['Label_tokens'].str.split()\n",
    "serialized_df['Label_tokens_list_int'] = serialized_df['Label_tokens_list'].apply(lambda x: list(map(int, x)))\n",
    "serialized_df = serialized_df[serialized_df['Label_tokens_list_int'].apply(lambda x: len(set(x)) > 1)]\n",
    "\n",
    "serialized_df['item_id_seq_test'] = serialized_df['Label_tokens_list'].apply(lambda x: ' '.join(x[:-1]))\n",
    "serialized_df['item_id_test'] = serialized_df['Label_tokens_list'].apply(lambda x: x[-1] if len(x) > 0 else None)\n",
    "serialized_df = serialized_df.drop(columns=['Label_tokens_list'])\n",
    "serialized_df = serialized_df[serialized_df['item_id_seq_test'] != ''].drop(columns=['Label_tokens'])\n",
    "\n",
    "serialized_df['Label_tokens_list'] = serialized_df['item_id_seq_test'].str.split()\n",
    "serialized_df['item_id_seq_train'] = serialized_df['Label_tokens_list'].apply(lambda x: ' '.join(x[:-1]))\n",
    "serialized_df['item_id_train'] = serialized_df['Label_tokens_list'].apply(lambda x: x[-1] if len(x) > 0 else None)\n",
    "serialized_df = serialized_df.drop(columns=['Label_tokens_list'])\n",
    "serialized_df = serialized_df[serialized_df['item_id_seq_train'] != '']\n",
    "\n",
    "serialized_df['vehicle'] = serialized_df['session'].map(session_vehicle_dict)\n",
    "serialized_df = serialized_df.drop(columns=['vehicle'])\n",
    "#serialized_df.rename(columns={'session': 'session_id'}, inplace=True)\n",
    "serialized_df['session_id'] = range(len(serialized_df))\n",
    "serialized_df['session_id'] = serialized_df['session_id'].astype(int)\n",
    "\n",
    "test_df = serialized_df[['session_id', 'item_id_seq_test', 'item_id_test']]\n",
    "train_df = serialized_df[['session_id', 'item_id_seq_train', 'item_id_train']]\n",
    "test_df.to_csv('../datasets/sequential/carsii_seq/test.tsv', sep='\\t', index=False)\n",
    "train_df.to_csv('../datasets/sequential/carsii_seq/train.tsv', sep='\\t', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "carsii",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
